{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_uM3iHlzBTTQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCH2J6P1BoSf",
        "outputId": "5e38bd1d-c8e8-4719-f7d1-cd25ac30a9ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = torch.Tensor([[[0.2,0.1,0.3],[0.5,0.1,0.1]]])\n",
        "B,S,E = inputs.size() # shape (batch_size,num_queries,d_model)\n",
        "# ***important \n",
        "inputs = inputs.reshape(S,B,E)  # shape (num_queries,batch_size,d_model)\n",
        "inputs.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "shape analysis is based on the case in which both batch_size and d_model are getting normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "UpUg58ixQXFx"
      },
      "outputs": [],
      "source": [
        "class LayerNormalization():\n",
        "  def __init__(self,parameter_shape,eps = 1e-5):\n",
        "    self.parameter_shape = parameter_shape\n",
        "    self.eps = eps\n",
        "    self.gamma = nn.Parameter(torch.ones(self.parameter_shape))\n",
        "    self.beta = nn.Parameter(torch.zeros(self.parameter_shape))\n",
        "  def forward(self,inputs):\n",
        "    dims = [-(i+1) for i in range(len(self.parameter_shape))]\n",
        "    mean = torch.mean(inputs,dim = dims,keepdim = True) # shape (num_queries,batch_size,1)\n",
        "    '''\n",
        "    inputs-mean shape is (num_queries,batch_size,d_model) {boroadcasting happens in  column}\n",
        "    '''\n",
        "    \n",
        "    var = ((inputs-mean)**2).mean(dim = dims,keepdim = True)  # shape (num_queries,batch_size,1)\n",
        "    std = torch.sqrt(var+self.eps)  # shape (num_queries,batch_size,1)\n",
        "    y = (inputs-mean)/std # shape (num_queries,batch_size,d_model) {due to broadcasting in column}\n",
        "    out = self.gamma * y + self.beta  # shape (num_queries,batch_size,d_model) {here also boroadcasting happens}\n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5z3myDjuWtr8"
      },
      "outputs": [],
      "source": [
        "parameter_shape = inputs.size()[-2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEceGxIKSqL4",
        "outputId": "8d8dd066-f7f9-4403-9c57-8fa50047e965"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
              "\n",
              "        [[ 1.4140, -0.7070, -0.7070]]], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "case1 = LayerNormalization(parameter_shape)\n",
        "case1.forward(inputs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
